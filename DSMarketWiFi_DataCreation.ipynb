{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "mZNS_yYFp8VJ",
        "34fd580ZcZOp",
        "o7MOY10u5x64",
        "rHqeyCQ-dDQU"
      ],
      "authorship_tag": "ABX9TyOy22i89Ct52tEyhtQQ950D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CristhianSeverino/customer-churn-and-contextual-chat/blob/staging/DSMarketWiFi_DataCreation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Customer Churn and Contextual Chat C4**\n",
        "\n",
        "> Este **Notebook** es una creación de: **Cristhian Calle Severino**☕.\n",
        "\n",
        "---\n",
        "\n",
        "* **GitHub**: https://github.com/CristhianSeverino\n",
        "* **LinkedIn**: https://www.linkedin.com/in/cristhianandrescalleseverino/\n",
        "\n",
        "---\n",
        "\n",
        "Este proyecto **emula un Data Product de Machine Learning (ML) con despliegue en AWS**. Se inspira en la arquitectura **Arana**.\n",
        "\n",
        "### **Incluye:**\n",
        "\n",
        "* **Creación de Datos Sintéticos**: Estos datos simulan usuarios de **MallPlaza**, un nombre genérico para un supuesto ficticio, dado que grandes centros comerciales homónimos existen en ciudades de América (como Santiago de Chile y Manizales, donde resido). Esta creación se basa en un supuesto de **Ingeniería y Arquitectura de Datos** que se detalla en el **Road Map**.\n",
        "\n",
        "---\n",
        "\n",
        "## **Módulos del Proyecto**📚\n",
        "\n",
        "El proyecto está estructurado en los siguientes **Módulos**:\n",
        "\n",
        "> * **Módulo 1 - Creación de Datos Sintéticos**: Emula un proceso **ELT** (Extracción, Carga y Transformación) de ingesta, carga y posterior transformación de datos. El resultado es un *dataset* limpio, listo para el entrenamiento de modelos de ML.\n",
        "> * **Módulo 2 - EDA (*Exploratory Data Analysis*)**: Análisis de datos exploratorio para la identificación de *insights* previos al ML. Incluye la búsqueda de características de enriquecimiento y el desarrollo de **Feature Engineering**.\n",
        "> * **Módulo 3 - Entrenamiento y Evaluación del Algoritmo**: Desarrollo del modelo, métricas de ajuste, evaluación de precisión y **Fine Tuning**.\n",
        "> * **Módulo 4 - Despliegue en AWS**: Implementación y prueba del despliegue en la nube.\n",
        "\n",
        "---\n",
        "\n",
        "## **Prerrequisitos y Recomendaciones**🧮\n",
        "\n",
        "**Nota**: Para este proyecto se emplea **AWS como *cloud platform***.\n",
        "\n",
        "Es **indispensable** poseer conocimientos en las siguientes tecnologías para comprender a cabalidad los aspectos técnicos:\n",
        "\n",
        "* **Lenguajes y Bases de Datos**: Python, SQL, VectorDB, Terraform\n",
        "* **Big Data y ML**: PySpark, Keras, Scikit-learn, PyTorch.\n",
        "* **Cloud y Herramientas MLOps**: AWS, Git.\n",
        "* **IA y Desarrollo de Aplicaciones**: LangChain, RAG, Streamlit, Gradio, API.\n",
        "\n",
        "Para una comprensión general del proyecto, **recomiendo encarecidamente la lectura del Road Map** y una revisión general de la documentación del código. 🦾\n",
        "\n",
        "> ¡Que disfrutes explorando este proyecto! Exitosa semana. 🐱‍🏍"
      ],
      "metadata": {
        "id": "ueJCmgvOW25a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Instalacción E Importación de Librerias // Istall & Import Librarys**📚"
      ],
      "metadata": {
        "id": "mZNS_yYFp8VJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install boto3\n",
        "print(\"=\"*150)\n",
        "print(\" \"*50+\"Boto install OK🐱‍🏍\")\n",
        "print(\"=\"*150)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oa063bsSYucp",
        "outputId": "65b456e9-8df8-40f7-9e6e-68c5a7947cbb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting boto3\n",
            "  Downloading boto3-1.40.40-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting botocore<1.41.0,>=1.40.40 (from boto3)\n",
            "  Downloading botocore-1.40.40-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.15.0,>=0.14.0 (from boto3)\n",
            "  Downloading s3transfer-0.14.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from botocore<1.41.0,>=1.40.40->boto3) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/dist-packages (from botocore<1.41.0,>=1.40.40->boto3) (2.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.40->boto3) (1.17.0)\n",
            "Downloading boto3-1.40.40-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.40.40-py3-none-any.whl (14.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.14.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.40.40 botocore-1.40.40 jmespath-1.0.1 s3transfer-0.14.0\n",
            "======================================================================================================================================================\n",
            "                                                  Boto install OK🐱‍🏍\n",
            "======================================================================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install awscli\n",
        "print(\"=\"*150)\n",
        "print(\" \"*50+\"AWS Cli Install OK\")\n",
        "print(\"=\"*150)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2vYfB9cr2n2",
        "outputId": "4bf8590e-4ddd-4859-b174-cab255276be2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting awscli\n",
            "  Downloading awscli-1.42.40-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: botocore==1.40.40 in /usr/local/lib/python3.12/dist-packages (from awscli) (1.40.40)\n",
            "Collecting docutils<=0.19,>=0.18.1 (from awscli)\n",
            "  Downloading docutils-0.19-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from awscli) (0.14.0)\n",
            "Requirement already satisfied: PyYAML<6.1,>=3.10 in /usr/local/lib/python3.12/dist-packages (from awscli) (6.0.2)\n",
            "Collecting colorama<0.4.7,>=0.2.5 (from awscli)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting rsa<4.8,>=3.1.2 (from awscli)\n",
            "  Downloading rsa-4.7.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from botocore==1.40.40->awscli) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from botocore==1.40.40->awscli) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/dist-packages (from botocore==1.40.40->awscli) (2.5.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from rsa<4.8,>=3.1.2->awscli) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.40.40->awscli) (1.17.0)\n",
            "Downloading awscli-1.42.40-py3-none-any.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading docutils-0.19-py3-none-any.whl (570 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m570.5/570.5 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
            "Installing collected packages: rsa, docutils, colorama, awscli\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.9.1\n",
            "    Uninstalling rsa-4.9.1:\n",
            "      Successfully uninstalled rsa-4.9.1\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.21.2\n",
            "    Uninstalling docutils-0.21.2:\n",
            "      Successfully uninstalled docutils-0.21.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sphinx 8.2.3 requires docutils<0.22,>=0.20, but you have docutils 0.19 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed awscli-1.42.40 colorama-0.4.6 docutils-0.19 rsa-4.7.2\n",
            "======================================================================================================================================================\n",
            "                                                  AWS Cli Install OK\n",
            "======================================================================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGAFVoZSJzN4",
        "outputId": "51f467ee-04d6-4d9d-dd1c-516d720b5a47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faker\n",
            "  Downloading faker-37.8.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.12/dist-packages (from faker) (2025.2)\n",
            "Downloading faker-37.8.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faker\n",
            "Successfully installed faker-37.8.0\n",
            "======================================================================================================================================================\n",
            "                                                  Librerias instaladas\n",
            "======================================================================================================================================================\n"
          ]
        }
      ],
      "source": [
        "!pip install faker\n",
        "print(\"=\"*150)\n",
        "print(\" \"*50+\"Librerias instaladas\")\n",
        "print(\"=\"*150)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================   Dependencys or Librarys   ==========================================\n",
        "# Enviroment Variables\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "#Data manipulation and generation\n",
        "from faker import Faker\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from datetime import datetime, timedelta\n",
        "import random\n",
        "import numpy as np\n",
        "# AWS\n",
        "import boto3\n",
        "\n",
        "print(\"=\"*150)\n",
        "print(\" \"*50+\"Librerias Importadas con Exito ☕\")\n",
        "print(\"=\"*150)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW29FEaJrJgW",
        "outputId": "ec5f9bd8-5f38-4322-9334-5f7c303ba0d4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "                                                  Librerias Importadas con Exito ☕\n",
            "======================================================================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Credenciales // Credentials**🎫"
      ],
      "metadata": {
        "id": "34fd580ZcZOp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ojo Actualizar Credenciales para el rol del Proyecto. Segun Data gobernance**👀"
      ],
      "metadata": {
        "id": "2JKeb3x8sTfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================   Variables de entoro o Credentials ==============================================================\n",
        "# AWS\n",
        "aws_access_key_id = userdata.get('AWS_ACCESS_KEY_ID')\n",
        "aws_secret_access_key = userdata.get('AWS_SECRET_ACCESS_KEY')\n",
        "region_name=userdata.get('AWS_REGION')\n",
        "bucket_name=userdata.get('s3_mallflow')\n",
        "s3 = boto3.client('s3',\n",
        "                  aws_access_key_id=aws_access_key_id,\n",
        "                  aws_secret_access_key=aws_secret_access_key,\n",
        "                  region_name=region_name)\n",
        "# Git Path\n",
        "git_path= userdata.get('GIT_PATH')\n",
        "user_git=userdata.get('USER_GIT')\n",
        "email_git=userdata.get('EMAIL_GIT')\n",
        "print(\"=\"*150)\n",
        "print(\" \"*50+\"Credenciales Cargadas\")\n",
        "print(\"=\"*150)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OK0skB9upScb",
        "outputId": "8f2a2d35-6c12-4a81-f7e7-ec39829daa9b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "                                                  Credenciales Cargadas\n",
            "======================================================================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generación de Data Set Sintetico // Generate Syntetic Data Set**🤖"
      ],
      "metadata": {
        "id": "o7MOY10u5x64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def generar_dataset_churn_wifi(n_muestras=1000, output_file='dataset_churn_mall_plaza.csv'):\n",
        "    fake = Faker('es_CL')\n",
        "    np.random.seed(42)\n",
        "    random.seed(42)\n",
        "\n",
        "    data = {\n",
        "        'customerId': [fake.uuid4() for _ in range(n_muestras)],\n",
        "        'name': [fake.name() for _ in range(n_muestras)],\n",
        "        'gender': np.random.choice(['Male', 'Female', 'Other'], n_muestras, p=[0.485, 0.51, 0.005]),\n",
        "        'age': np.random.randint(18, 81, n_muestras),\n",
        "        'visits': np.random.randint(1, 31, n_muestras),\n",
        "        'avg_session_time': np.random.uniform(5, 120, n_muestras).round(2),\n",
        "        'complaints': np.random.randint(0, 11, n_muestras),\n",
        "        'location': [fake.random_element(elements=['Mall Central', 'Mega Tienda', 'Cinemas', 'Electronica', 'Mall Comidas 1', 'Mall Comidas 2', 'Gimnasios', 'Arcades']) for _ in range(n_muestras)],\n",
        "        'device_type': np.random.choice(['Smartphone', 'Laptop', 'Tablet'], n_muestras, p=[0.85, 0.08, 0.07]),\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "    df['total_session_time'] = df['visits'] * df['avg_session_time'] + np.random.normal(0, 10, n_muestras)\n",
        "    df['complaints_per_visit'] = np.where(df['visits'] > 0, df['complaints'] / df['visits'], 0)\n",
        "    df['log_visits'] = np.log1p(df['visits'])\n",
        "    bins = [18, 30, 50, 81]; labels = ['Young', 'Adult', 'Senior']\n",
        "    df['age_group'] = pd.cut(df['age'], bins=bins, labels=labels, right=False)\n",
        "    df['high_complaints_flag'] = (df['complaints'] > 5).astype(int)\n",
        "    max_visits = 30; max_session = 120\n",
        "    df['engagement_score'] = (df['visits']/max_visits) * (df['avg_session_time']/max_session) * (1 - df['complaints_per_visit'].clip(0,1))\n",
        "    df['gender_age_ifemale'] = df['age'] * (df['gender'] == 'Female').astype(int)\n",
        "    df['gender_age_imale'] = df['age'] * (df['gender'] == 'Male').astype(int)\n",
        "    df['gender_age_iother'] = df['age'] * (df['gender'] == 'other').astype(int)\n",
        "    today = datetime.now()\n",
        "    df['last_visit_date'] = [today - timedelta(days=np.random.randint(0,31)) for _ in range(n_muestras)]\n",
        "    df['recency_days'] = (today - df['last_visit_date']).dt.days\n",
        "    df['tenure_months'] = np.random.randint(6, 61, n_muestras)\n",
        "    df['data_usage_total'] = df['total_session_time'] * np.random.uniform(0.5, 2.0, n_muestras)\n",
        "\n",
        "    # Genera churn basado en features\n",
        "    logit = - (df['visits'] / 30) * 2 - (df['avg_session_time'] / 120) * 2 + (df['complaints'] / 10) * 4 + np.random.normal(0, 0.5, n_muestras)\n",
        "    p_churn = 1 / (1 + np.exp(-logit))\n",
        "    df['churn'] = np.where(np.random.rand(n_muestras) < p_churn, 'Yes', 'No')\n",
        "\n",
        "    # Opcional: One-hot encoding para emular dataset listo para ML\n",
        "    df = pd.get_dummies(df, columns=['gender', 'location', 'device_type', 'age_group', 'churn'])\n",
        "\n",
        "    df.to_csv(output_file, index=False)\n",
        "    print(f\"Dataset Generado 🧮 y guardado en '{output_file}' con {n_muestras} muestras\")\n",
        "    return df"
      ],
      "metadata": {
        "id": "vSGLrTr0sRRh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = generar_dataset_churn_wifi(n_muestras=100000, output_file='churn_abril_mallplaza.csv' )\n",
        "\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BxyDQaAs3_J",
        "outputId": "b0c43c63-98c1-4993-82b9-72a6bc46c77c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Generado 🧮 y guardado en 'churn_abril_mallplaza.csv' con 100000 muestras\n",
            "                             customerId                               name  \\\n",
            "0  0a415de2-2469-4f34-a77b-a947eef941e9         Matías Frank Méndez Campos   \n",
            "1  0d3129b4-2525-4235-8765-77eaa606d6cf  Benjamín Joaquín Guajardo Cabrera   \n",
            "2  5b19695e-2fe1-4375-b723-6aaa414f49b9         Juan Claudio Vera Riquelme   \n",
            "3  de67247b-dded-46c2-aeba-1bf16cc73113                     Alejandra Sáez   \n",
            "4  b2609f86-faf8-4d2e-a569-ba76c4f559d5                Marta Meza González   \n",
            "\n",
            "   age  visits  avg_session_time  complaints  total_session_time  \\\n",
            "0   51       3             32.57           0           97.120068   \n",
            "1   25      13             64.52           8          826.446774   \n",
            "2   79      27             84.52           2         2287.022366   \n",
            "3   32      28             65.70           1         1828.755038   \n",
            "4   74      20             27.03           8          543.183295   \n",
            "\n",
            "   complaints_per_visit  log_visits  high_complaints_flag  ...  \\\n",
            "0              0.000000    1.386294                     0  ...   \n",
            "1              0.615385    2.639057                     1  ...   \n",
            "2              0.074074    3.332205                     0  ...   \n",
            "3              0.035714    3.367296                     0  ...   \n",
            "4              0.400000    3.044522                     1  ...   \n",
            "\n",
            "   location_Mall Comidas 2  location_Mega Tienda  device_type_Laptop  \\\n",
            "0                     True                 False               False   \n",
            "1                    False                 False               False   \n",
            "2                    False                 False               False   \n",
            "3                    False                 False                True   \n",
            "4                    False                 False               False   \n",
            "\n",
            "   device_type_Smartphone device_type_Tablet  age_group_Young  \\\n",
            "0                    True              False            False   \n",
            "1                    True              False             True   \n",
            "2                    True              False            False   \n",
            "3                   False              False            False   \n",
            "4                    True              False            False   \n",
            "\n",
            "   age_group_Adult  age_group_Senior  churn_No  churn_Yes  \n",
            "0            False              True      True      False  \n",
            "1            False             False     False       True  \n",
            "2            False              True      True      False  \n",
            "3             True             False      True      False  \n",
            "4            False              True     False       True  \n",
            "\n",
            "[5 rows x 37 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Carga de Datos y envio para Downs Stakeholders Bucket de AWS // Load Data for Delivery** 💾"
      ],
      "metadata": {
        "id": "rHqeyCQ-dDQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rear los archivos de configuración de AWS\n",
        "# Directorio y Archivo de Credenciales\n",
        "aws_dir = '/root/.aws'\n",
        "os.makedirs(aws_dir, exist_ok=True)\n",
        "with open(os.path.join(aws_dir, 'credentials'), 'w') as f:\n",
        "    f.write(f'[default]\\n')\n",
        "    f.write(f'aws_access_key_id = {aws_access_key_id}\\n')\n",
        "    f.write(f'aws_secret_access_key = {aws_secret_access_key}\\n')\n",
        "# Write 'config'\n",
        "with open(os.path.join(aws_dir, 'config'), 'w') as f:\n",
        "    f.write(f'[default]\\n')\n",
        "    f.write(f'region = {region_name}\\n')\n",
        "print(\"Archivos de cofiguracion de AWs creados Exitosamente ☕\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAFVfm6x7sj5",
        "outputId": "cece72f5-8236-475d-f9a6-a583c002c557"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivos de cofiguracion de AWs creados Exitosamente ☕\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_to_s3(local_file,s3_path):\n",
        "    s3.upload_file(local_file, bucket_name, s3_path)\n",
        "    print(f\"Subido {local_file} a s3://{bucket_name}/{s3_path}\")\n",
        "upload_to_s3('/content/churn_abril_mallplaza.csv', 'warehouse-ml/churn_abril_mallplaza/churn_abril_mallplaza.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAqiYh5B_CgO",
        "outputId": "41250cac-2b86-4bd4-8430-3e8c4048dd4a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subido /content/churn_abril_mallplaza.csv a s3://mall-flow/warehouse-ml/churn_abril_mallplaza/churn_abril_mallplaza.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Verifica la Creacion de los CSV en el icono de carpeta.costado izquiero de colab***\n",
        "\n",
        "> **Diviertete Explorando este Proyecto**🐱‍👓\n",
        "\n",
        "🧭Si te fue de ayuda este proyecto, pasa por mi linkedin y cuentame como te ayudo ☕\n"
      ],
      "metadata": {
        "id": "qo5dqf0cdb7t"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UVpTOj-JfbCL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}