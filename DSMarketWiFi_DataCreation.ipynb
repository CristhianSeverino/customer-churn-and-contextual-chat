{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "mZNS_yYFp8VJ",
        "34fd580ZcZOp",
        "o7MOY10u5x64",
        "rHqeyCQ-dDQU"
      ],
      "authorship_tag": "ABX9TyOy22i89Ct52tEyhtQQ950D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CristhianSeverino/customer-churn-and-contextual-chat/blob/staging/DSMarketWiFi_DataCreation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Customer Churn and Contextual Chat C4**\n",
        "\n",
        "> Este **Notebook** es una creaciÃ³n de: **Cristhian Calle Severino**â˜•.\n",
        "\n",
        "---\n",
        "\n",
        "* **GitHub**: https://github.com/CristhianSeverino\n",
        "* **LinkedIn**: https://www.linkedin.com/in/cristhianandrescalleseverino/\n",
        "\n",
        "---\n",
        "\n",
        "Este proyecto **emula un Data Product de Machine Learning (ML) con despliegue en AWS**. Se inspira en la arquitectura **Arana**.\n",
        "\n",
        "### **Incluye:**\n",
        "\n",
        "* **CreaciÃ³n de Datos SintÃ©ticos**: Estos datos simulan usuarios de **MallPlaza**, un nombre genÃ©rico para un supuesto ficticio, dado que grandes centros comerciales homÃ³nimos existen en ciudades de AmÃ©rica (como Santiago de Chile y Manizales, donde resido). Esta creaciÃ³n se basa en un supuesto de **IngenierÃ­a y Arquitectura de Datos** que se detalla en el **Road Map**.\n",
        "\n",
        "---\n",
        "\n",
        "## **MÃ³dulos del Proyecto**ğŸ“š\n",
        "\n",
        "El proyecto estÃ¡ estructurado en los siguientes **MÃ³dulos**:\n",
        "\n",
        "> * **MÃ³dulo 1 - CreaciÃ³n de Datos SintÃ©ticos**: Emula un proceso **ELT** (ExtracciÃ³n, Carga y TransformaciÃ³n) de ingesta, carga y posterior transformaciÃ³n de datos. El resultado es un *dataset* limpio, listo para el entrenamiento de modelos de ML.\n",
        "> * **MÃ³dulo 2 - EDA (*Exploratory Data Analysis*)**: AnÃ¡lisis de datos exploratorio para la identificaciÃ³n de *insights* previos al ML. Incluye la bÃºsqueda de caracterÃ­sticas de enriquecimiento y el desarrollo de **Feature Engineering**.\n",
        "> * **MÃ³dulo 3 - Entrenamiento y EvaluaciÃ³n del Algoritmo**: Desarrollo del modelo, mÃ©tricas de ajuste, evaluaciÃ³n de precisiÃ³n y **Fine Tuning**.\n",
        "> * **MÃ³dulo 4 - Despliegue en AWS**: ImplementaciÃ³n y prueba del despliegue en la nube.\n",
        "\n",
        "---\n",
        "\n",
        "## **Prerrequisitos y Recomendaciones**ğŸ§®\n",
        "\n",
        "**Nota**: Para este proyecto se emplea **AWS como *cloud platform***.\n",
        "\n",
        "Es **indispensable** poseer conocimientos en las siguientes tecnologÃ­as para comprender a cabalidad los aspectos tÃ©cnicos:\n",
        "\n",
        "* **Lenguajes y Bases de Datos**: Python, SQL, VectorDB, Terraform\n",
        "* **Big Data y ML**: PySpark, Keras, Scikit-learn, PyTorch.\n",
        "* **Cloud y Herramientas MLOps**: AWS, Git.\n",
        "* **IA y Desarrollo de Aplicaciones**: LangChain, RAG, Streamlit, Gradio, API.\n",
        "\n",
        "Para una comprensiÃ³n general del proyecto, **recomiendo encarecidamente la lectura del Road Map** y una revisiÃ³n general de la documentaciÃ³n del cÃ³digo. ğŸ¦¾\n",
        "\n",
        "> Â¡Que disfrutes explorando este proyecto! Exitosa semana. ğŸ±â€ğŸ"
      ],
      "metadata": {
        "id": "ueJCmgvOW25a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **InstalacciÃ³n E ImportaciÃ³n de Librerias // Istall & Import Librarys**ğŸ“š"
      ],
      "metadata": {
        "id": "mZNS_yYFp8VJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install boto3\n",
        "print(\"=\"*150)\n",
        "print(\" \"*50+\"Boto install OKğŸ±â€ğŸ\")\n",
        "print(\"=\"*150)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oa063bsSYucp",
        "outputId": "65b456e9-8df8-40f7-9e6e-68c5a7947cbb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting boto3\n",
            "  Downloading boto3-1.40.40-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting botocore<1.41.0,>=1.40.40 (from boto3)\n",
            "  Downloading botocore-1.40.40-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.15.0,>=0.14.0 (from boto3)\n",
            "  Downloading s3transfer-0.14.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from botocore<1.41.0,>=1.40.40->boto3) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/dist-packages (from botocore<1.41.0,>=1.40.40->boto3) (2.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.40->boto3) (1.17.0)\n",
            "Downloading boto3-1.40.40-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.40.40-py3-none-any.whl (14.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.14.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.40.40 botocore-1.40.40 jmespath-1.0.1 s3transfer-0.14.0\n",
            "======================================================================================================================================================\n",
            "                                                  Boto install OKğŸ±â€ğŸ\n",
            "======================================================================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install awscli\n",
        "print(\"=\"*150)\n",
        "print(\" \"*50+\"AWS Cli Install OK\")\n",
        "print(\"=\"*150)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2vYfB9cr2n2",
        "outputId": "4bf8590e-4ddd-4859-b174-cab255276be2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting awscli\n",
            "  Downloading awscli-1.42.40-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: botocore==1.40.40 in /usr/local/lib/python3.12/dist-packages (from awscli) (1.40.40)\n",
            "Collecting docutils<=0.19,>=0.18.1 (from awscli)\n",
            "  Downloading docutils-0.19-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from awscli) (0.14.0)\n",
            "Requirement already satisfied: PyYAML<6.1,>=3.10 in /usr/local/lib/python3.12/dist-packages (from awscli) (6.0.2)\n",
            "Collecting colorama<0.4.7,>=0.2.5 (from awscli)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting rsa<4.8,>=3.1.2 (from awscli)\n",
            "  Downloading rsa-4.7.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from botocore==1.40.40->awscli) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from botocore==1.40.40->awscli) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/dist-packages (from botocore==1.40.40->awscli) (2.5.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from rsa<4.8,>=3.1.2->awscli) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.40.40->awscli) (1.17.0)\n",
            "Downloading awscli-1.42.40-py3-none-any.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading docutils-0.19-py3-none-any.whl (570 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m570.5/570.5 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
            "Installing collected packages: rsa, docutils, colorama, awscli\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.9.1\n",
            "    Uninstalling rsa-4.9.1:\n",
            "      Successfully uninstalled rsa-4.9.1\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.21.2\n",
            "    Uninstalling docutils-0.21.2:\n",
            "      Successfully uninstalled docutils-0.21.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sphinx 8.2.3 requires docutils<0.22,>=0.20, but you have docutils 0.19 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed awscli-1.42.40 colorama-0.4.6 docutils-0.19 rsa-4.7.2\n",
            "======================================================================================================================================================\n",
            "                                                  AWS Cli Install OK\n",
            "======================================================================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGAFVoZSJzN4",
        "outputId": "51f467ee-04d6-4d9d-dd1c-516d720b5a47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faker\n",
            "  Downloading faker-37.8.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.12/dist-packages (from faker) (2025.2)\n",
            "Downloading faker-37.8.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faker\n",
            "Successfully installed faker-37.8.0\n",
            "======================================================================================================================================================\n",
            "                                                  Librerias instaladas\n",
            "======================================================================================================================================================\n"
          ]
        }
      ],
      "source": [
        "!pip install faker\n",
        "print(\"=\"*150)\n",
        "print(\" \"*50+\"Librerias instaladas\")\n",
        "print(\"=\"*150)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================   Dependencys or Librarys   ==========================================\n",
        "# Enviroment Variables\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "#Data manipulation and generation\n",
        "from faker import Faker\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from datetime import datetime, timedelta\n",
        "import random\n",
        "import numpy as np\n",
        "# AWS\n",
        "import boto3\n",
        "\n",
        "print(\"=\"*150)\n",
        "print(\" \"*50+\"Librerias Importadas con Exito â˜•\")\n",
        "print(\"=\"*150)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW29FEaJrJgW",
        "outputId": "ec5f9bd8-5f38-4322-9334-5f7c303ba0d4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "                                                  Librerias Importadas con Exito â˜•\n",
            "======================================================================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Credenciales // Credentials**ğŸ«"
      ],
      "metadata": {
        "id": "34fd580ZcZOp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ojo Actualizar Credenciales para el rol del Proyecto. Segun Data gobernance**ğŸ‘€"
      ],
      "metadata": {
        "id": "2JKeb3x8sTfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================   Variables de entoro o Credentials ==============================================================\n",
        "# AWS\n",
        "aws_access_key_id = userdata.get('AWS_ACCESS_KEY_ID')\n",
        "aws_secret_access_key = userdata.get('AWS_SECRET_ACCESS_KEY')\n",
        "region_name=userdata.get('AWS_REGION')\n",
        "bucket_name=userdata.get('s3_mallflow')\n",
        "s3 = boto3.client('s3',\n",
        "                  aws_access_key_id=aws_access_key_id,\n",
        "                  aws_secret_access_key=aws_secret_access_key,\n",
        "                  region_name=region_name)\n",
        "# Git Path\n",
        "git_path= userdata.get('GIT_PATH')\n",
        "user_git=userdata.get('USER_GIT')\n",
        "email_git=userdata.get('EMAIL_GIT')\n",
        "print(\"=\"*150)\n",
        "print(\" \"*50+\"Credenciales Cargadas\")\n",
        "print(\"=\"*150)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OK0skB9upScb",
        "outputId": "8f2a2d35-6c12-4a81-f7e7-ec39829daa9b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "                                                  Credenciales Cargadas\n",
            "======================================================================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GeneraciÃ³n de Data Set Sintetico // Generate Syntetic Data Set**ğŸ¤–"
      ],
      "metadata": {
        "id": "o7MOY10u5x64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def generar_dataset_churn_wifi(n_muestras=1000, output_file='dataset_churn_mall_plaza.csv'):\n",
        "    fake = Faker('es_CL')\n",
        "    np.random.seed(42)\n",
        "    random.seed(42)\n",
        "\n",
        "    data = {\n",
        "        'customerId': [fake.uuid4() for _ in range(n_muestras)],\n",
        "        'name': [fake.name() for _ in range(n_muestras)],\n",
        "        'gender': np.random.choice(['Male', 'Female', 'Other'], n_muestras, p=[0.485, 0.51, 0.005]),\n",
        "        'age': np.random.randint(18, 81, n_muestras),\n",
        "        'visits': np.random.randint(1, 31, n_muestras),\n",
        "        'avg_session_time': np.random.uniform(5, 120, n_muestras).round(2),\n",
        "        'complaints': np.random.randint(0, 11, n_muestras),\n",
        "        'location': [fake.random_element(elements=['Mall Central', 'Mega Tienda', 'Cinemas', 'Electronica', 'Mall Comidas 1', 'Mall Comidas 2', 'Gimnasios', 'Arcades']) for _ in range(n_muestras)],\n",
        "        'device_type': np.random.choice(['Smartphone', 'Laptop', 'Tablet'], n_muestras, p=[0.85, 0.08, 0.07]),\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "    df['total_session_time'] = df['visits'] * df['avg_session_time'] + np.random.normal(0, 10, n_muestras)\n",
        "    df['complaints_per_visit'] = np.where(df['visits'] > 0, df['complaints'] / df['visits'], 0)\n",
        "    df['log_visits'] = np.log1p(df['visits'])\n",
        "    bins = [18, 30, 50, 81]; labels = ['Young', 'Adult', 'Senior']\n",
        "    df['age_group'] = pd.cut(df['age'], bins=bins, labels=labels, right=False)\n",
        "    df['high_complaints_flag'] = (df['complaints'] > 5).astype(int)\n",
        "    max_visits = 30; max_session = 120\n",
        "    df['engagement_score'] = (df['visits']/max_visits) * (df['avg_session_time']/max_session) * (1 - df['complaints_per_visit'].clip(0,1))\n",
        "    df['gender_age_ifemale'] = df['age'] * (df['gender'] == 'Female').astype(int)\n",
        "    df['gender_age_imale'] = df['age'] * (df['gender'] == 'Male').astype(int)\n",
        "    df['gender_age_iother'] = df['age'] * (df['gender'] == 'other').astype(int)\n",
        "    today = datetime.now()\n",
        "    df['last_visit_date'] = [today - timedelta(days=np.random.randint(0,31)) for _ in range(n_muestras)]\n",
        "    df['recency_days'] = (today - df['last_visit_date']).dt.days\n",
        "    df['tenure_months'] = np.random.randint(6, 61, n_muestras)\n",
        "    df['data_usage_total'] = df['total_session_time'] * np.random.uniform(0.5, 2.0, n_muestras)\n",
        "\n",
        "    # Genera churn basado en features\n",
        "    logit = - (df['visits'] / 30) * 2 - (df['avg_session_time'] / 120) * 2 + (df['complaints'] / 10) * 4 + np.random.normal(0, 0.5, n_muestras)\n",
        "    p_churn = 1 / (1 + np.exp(-logit))\n",
        "    df['churn'] = np.where(np.random.rand(n_muestras) < p_churn, 'Yes', 'No')\n",
        "\n",
        "    # Opcional: One-hot encoding para emular dataset listo para ML\n",
        "    df = pd.get_dummies(df, columns=['gender', 'location', 'device_type', 'age_group', 'churn'])\n",
        "\n",
        "    df.to_csv(output_file, index=False)\n",
        "    print(f\"Dataset Generado ğŸ§® y guardado en '{output_file}' con {n_muestras} muestras\")\n",
        "    return df"
      ],
      "metadata": {
        "id": "vSGLrTr0sRRh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = generar_dataset_churn_wifi(n_muestras=100000, output_file='churn_abril_mallplaza.csv' )\n",
        "\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BxyDQaAs3_J",
        "outputId": "b0c43c63-98c1-4993-82b9-72a6bc46c77c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Generado ğŸ§® y guardado en 'churn_abril_mallplaza.csv' con 100000 muestras\n",
            "                             customerId                               name  \\\n",
            "0  0a415de2-2469-4f34-a77b-a947eef941e9         MatÃ­as Frank MÃ©ndez Campos   \n",
            "1  0d3129b4-2525-4235-8765-77eaa606d6cf  BenjamÃ­n JoaquÃ­n Guajardo Cabrera   \n",
            "2  5b19695e-2fe1-4375-b723-6aaa414f49b9         Juan Claudio Vera Riquelme   \n",
            "3  de67247b-dded-46c2-aeba-1bf16cc73113                     Alejandra SÃ¡ez   \n",
            "4  b2609f86-faf8-4d2e-a569-ba76c4f559d5                Marta Meza GonzÃ¡lez   \n",
            "\n",
            "   age  visits  avg_session_time  complaints  total_session_time  \\\n",
            "0   51       3             32.57           0           97.120068   \n",
            "1   25      13             64.52           8          826.446774   \n",
            "2   79      27             84.52           2         2287.022366   \n",
            "3   32      28             65.70           1         1828.755038   \n",
            "4   74      20             27.03           8          543.183295   \n",
            "\n",
            "   complaints_per_visit  log_visits  high_complaints_flag  ...  \\\n",
            "0              0.000000    1.386294                     0  ...   \n",
            "1              0.615385    2.639057                     1  ...   \n",
            "2              0.074074    3.332205                     0  ...   \n",
            "3              0.035714    3.367296                     0  ...   \n",
            "4              0.400000    3.044522                     1  ...   \n",
            "\n",
            "   location_Mall Comidas 2  location_Mega Tienda  device_type_Laptop  \\\n",
            "0                     True                 False               False   \n",
            "1                    False                 False               False   \n",
            "2                    False                 False               False   \n",
            "3                    False                 False                True   \n",
            "4                    False                 False               False   \n",
            "\n",
            "   device_type_Smartphone device_type_Tablet  age_group_Young  \\\n",
            "0                    True              False            False   \n",
            "1                    True              False             True   \n",
            "2                    True              False            False   \n",
            "3                   False              False            False   \n",
            "4                    True              False            False   \n",
            "\n",
            "   age_group_Adult  age_group_Senior  churn_No  churn_Yes  \n",
            "0            False              True      True      False  \n",
            "1            False             False     False       True  \n",
            "2            False              True      True      False  \n",
            "3             True             False      True      False  \n",
            "4            False              True     False       True  \n",
            "\n",
            "[5 rows x 37 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Carga de Datos y envio para Downs Stakeholders Bucket de AWS // Load Data for Delivery** ğŸ’¾"
      ],
      "metadata": {
        "id": "rHqeyCQ-dDQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rear los archivos de configuraciÃ³n de AWS\n",
        "# Directorio y Archivo de Credenciales\n",
        "aws_dir = '/root/.aws'\n",
        "os.makedirs(aws_dir, exist_ok=True)\n",
        "with open(os.path.join(aws_dir, 'credentials'), 'w') as f:\n",
        "    f.write(f'[default]\\n')\n",
        "    f.write(f'aws_access_key_id = {aws_access_key_id}\\n')\n",
        "    f.write(f'aws_secret_access_key = {aws_secret_access_key}\\n')\n",
        "# Write 'config'\n",
        "with open(os.path.join(aws_dir, 'config'), 'w') as f:\n",
        "    f.write(f'[default]\\n')\n",
        "    f.write(f'region = {region_name}\\n')\n",
        "print(\"Archivos de cofiguracion de AWs creados Exitosamente â˜•\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAFVfm6x7sj5",
        "outputId": "cece72f5-8236-475d-f9a6-a583c002c557"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivos de cofiguracion de AWs creados Exitosamente â˜•\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_to_s3(local_file,s3_path):\n",
        "    s3.upload_file(local_file, bucket_name, s3_path)\n",
        "    print(f\"Subido {local_file} a s3://{bucket_name}/{s3_path}\")\n",
        "upload_to_s3('/content/churn_abril_mallplaza.csv', 'warehouse-ml/churn_abril_mallplaza/churn_abril_mallplaza.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAqiYh5B_CgO",
        "outputId": "41250cac-2b86-4bd4-8430-3e8c4048dd4a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subido /content/churn_abril_mallplaza.csv a s3://mall-flow/warehouse-ml/churn_abril_mallplaza/churn_abril_mallplaza.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Verifica la Creacion de los CSV en el icono de carpeta.costado izquiero de colab***\n",
        "\n",
        "> **Diviertete Explorando este Proyecto**ğŸ±â€ğŸ‘“\n",
        "\n",
        "ğŸ§­Si te fue de ayuda este proyecto, pasa por mi linkedin y cuentame como te ayudo â˜•\n"
      ],
      "metadata": {
        "id": "qo5dqf0cdb7t"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UVpTOj-JfbCL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}